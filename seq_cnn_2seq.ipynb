{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "general_AI.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDEmbbIQEGSV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "sys.stdout.write(\"\\033[1;34m\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        " \n",
        "train_path_im='/content/drive/My Drive/GeneralYolodata/'\n",
        "dir_path_conversation = '/content/drive/My Drive/chatterbot_dataset_ita'\n",
        "len_data_vqa=2000\n",
        "input_im_size=64\n",
        "num_epochs=2000\n",
        "batch_size=128\n",
        " \n",
        "#questions and answers\n",
        "pre_ques = ['che cosa vedi']\n",
        "pre_answers = ['vedo una camera da letto', 'vedo una città con dei palazzi', 'ci sono delle persone ',\n",
        "               'una foresta con degli alberi', 'sono davanti ad una montagna', 'questo potrebbe essere un cane',\n",
        "               'un gatto', 'il traffico con delle macchine', 'vedo una scrivania', 'questa dovrebbe essere una sedia']\n",
        "questions = []\n",
        "answers = []\n",
        " \n",
        "for i in range(len_data_vqa):\n",
        "    questions.append(pre_ques[0])\n",
        " \n",
        "for i in range(int(len_data_vqa / 200)):\n",
        "    for n in range(200):\n",
        "        answers.append(pre_answers[i])\n",
        " \n",
        "for filepath in os.listdir(dir_path_conversation):\n",
        "    stream = open(dir_path_conversation + os.sep + filepath, 'r', encoding='utf-8')\n",
        "    text = stream.readlines()\n",
        "    for i in range(int(len(text) / 2) - 6):\n",
        "        questions.append(text[i + i].rstrip('\\n'))\n",
        "        answers.append(text[i + i + 1].rstrip('\\n'))\n",
        " \n",
        "#images\n",
        "images=[]\n",
        "for i in range(len_data_vqa):\n",
        "  i=i+1\n",
        "  im=cv2.resize(cv2.imread(train_path_im+ str(i)+ '.jpg'),(input_im_size,input_im_size))/255.0\n",
        "  images.append(im)\n",
        " \n",
        "for i in range(len(questions)-len_data_vqa):\n",
        "  im = cv2.resize(cv2.imread(train_path_im + 'faces_1.jpg'), (input_im_size, input_im_size)) / 255.0\n",
        "  images.append(im)\n",
        " \n",
        "images=np.expand_dims(images,1)\n",
        "print('Images shape =',images.shape)\n",
        " \n",
        "#questions\n",
        "questions_lines = questions\n",
        " \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts( questions_lines )\n",
        "tokenized_eng_lines = tokenizer.texts_to_sequences( questions_lines )\n",
        " \n",
        "length_list = []\n",
        "for token_seq in tokenized_eng_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_input_length = np.amax( length_list )\n",
        "print( 'questions max length is {}'.format( max_input_length ))\n",
        " \n",
        "padded_eng_lines = pad_sequences( tokenized_eng_lines , maxlen=max_input_length , padding='post' )\n",
        "encoder_input_data = np.array( np.expand_dims(padded_eng_lines, 1))\n",
        "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
        " \n",
        "eng_word_dict = tokenizer.word_index\n",
        "num_eng_tokens = len( eng_word_dict )+1\n",
        "print( 'Number of questions tokens = {}'.format( num_eng_tokens))\n",
        " \n",
        "#answers\n",
        "answer_lines = []\n",
        "lines_answers=answers\n",
        "for line in range( len(lines_answers)):\n",
        "    answer_lines.append( '<START> ' + str(lines_answers[line]) + ' <END>' )\n",
        " \n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts( answer_lines )\n",
        "tokenized_mar_lines = tokenizer.texts_to_sequences( answer_lines )\n",
        " \n",
        "length_list = []\n",
        "for token_seq in tokenized_mar_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_output_length = np.amax( length_list )\n",
        "print( 'Answers max length is {}'.format( max_output_length ))\n",
        " \n",
        "padded_mar_lines = pad_sequences( tokenized_mar_lines , maxlen=max_output_length, padding='post' )\n",
        "decoder_input_data = np.array( padded_mar_lines )\n",
        "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
        " \n",
        "mar_word_dict = tokenizer.word_index\n",
        "num_mar_tokens = len( mar_word_dict )+1\n",
        "print( 'Number of Answers tokens = {}'.format( num_mar_tokens))\n",
        " \n",
        "#decoder target data\n",
        "decoder_target_data = list()\n",
        "for token_seq in tokenized_mar_lines:\n",
        "    decoder_target_data.append(token_seq[1:])\n",
        " \n",
        "padded_mar_lines = pad_sequences(decoder_target_data, maxlen=max_output_length, padding='post')\n",
        "onehot_mar_lines = to_categorical(padded_mar_lines, num_mar_tokens)\n",
        "decoder_target_data = np.array(onehot_mar_lines)\n",
        "print('Decoder target data shape -> {}'.format(decoder_target_data.shape))\n",
        " \n",
        "#cnn model\n",
        "vision_model=keras.models.Sequential()\n",
        "vision_model.add(keras.layers.Conv2D(32, kernel_size=(3,3),padding='same',activation='elu',input_shape=(input_im_size,input_im_size,3)))\n",
        "vision_model.add(keras.layers.Conv2D(32, kernel_size=(3,3),activation='elu'))\n",
        "vision_model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "vision_model.add(keras.layers.Dropout(0.1))\n",
        "vision_model.add(keras.layers.Conv2D(64, kernel_size=(3,3),padding='same',activation='elu'))\n",
        "vision_model.add(keras.layers.Conv2D(64, kernel_size=(3,3),activation='elu'))\n",
        "vision_model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "vision_model.add(keras.layers.Dropout(0.2))\n",
        "vision_model.add(keras.layers.Conv2D(128,kernel_size=(3,3),padding='same',activation='elu'))\n",
        "vision_model.add(keras.layers.Conv2D(128,kernel_size=(3,3),activation='elu'))\n",
        "vision_model.add(keras.layers.Conv2D(128,kernel_size=(3,3),activation='elu'))\n",
        "vision_model.add(keras.layers.MaxPooling2D((2,2)))\n",
        "vision_model.add(keras.layers.Dropout(0.2))\n",
        "vision_model.add(keras.layers.Flatten())\n",
        "vision_model.add(keras.layers.BatchNormalization())\n",
        " \n",
        "#seq2seq + cnn model\n",
        "image_input=keras.layers.Input(shape=(1,input_im_size,input_im_size, 3))\n",
        "cnn_lstm=keras.models.Sequential()\n",
        "cnn_lstm.add(keras.layers.TimeDistributed(vision_model,input_shape=(1,input_im_size,input_im_size, 3)))\n",
        "encoded_image=cnn_lstm(image_input)\n",
        " \n",
        "encoder_inputs = keras.layers.Input(shape=( 1,None  ))\n",
        "encoder_embedding = keras.layers.TimeDistributed(keras.layers.Embedding( num_eng_tokens, 128 , mask_zero=True ) )(encoder_inputs)\n",
        "pre_lstm=keras.layers.TimeDistributed(keras.layers.LSTM( 64  ))(encoder_embedding)\n",
        "merged=keras.layers.concatenate([encoded_image,pre_lstm])\n",
        "encoder_outputs , state_h , state_c = keras.layers.LSTM( 64 , return_state=True  )(merged)\n",
        "encoder_states = [ state_h , state_c ]\n",
        " \n",
        "decoder_inputs = keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = keras.layers.Embedding( num_mar_tokens, 128 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = keras.layers.LSTM( 64 ,return_state=True,return_sequences=True)\n",
        "decoder_outputs , _ , _ = decoder_lstm (decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = keras.layers.Dense( num_mar_tokens , activation=keras.activations.softmax )\n",
        "output_0 = decoder_dense (decoder_outputs )\n",
        " \n",
        "vqaseq_model=keras.models.Model([image_input,encoder_inputs,decoder_inputs],output_0)\n",
        " \n",
        "#compile model\n",
        "vqaseq_model.compile(\n",
        "  optimizer=keras.optimizers.Adam(),\n",
        "  loss='categorical_crossentropy',\n",
        "  metrics=['accuracy'],\n",
        ")\n",
        "vqaseq_model.summary()\n",
        " \n",
        "vqaseq_model.fit([images,encoder_input_data , decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=num_epochs)\n",
        " \n",
        "def make_inference_models():\n",
        "    encoder_model = keras.models.Model([image_input,encoder_inputs], encoder_states)\n",
        " \n",
        "    decoder_state_input_h = keras.layers.Input(shape=(64,))\n",
        "    decoder_state_input_c = keras.layers.Input(shape=(64,))\n",
        " \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        " \n",
        "    decoder_outputs_, state_h_, state_c_ = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h_, state_c_]\n",
        "    decoder_outputs_ = decoder_dense(decoder_outputs_)\n",
        "    decoder_model = keras.models.Model([decoder_inputs] + decoder_states_inputs,[decoder_outputs_] + decoder_states)\n",
        " \n",
        "    return encoder_model, decoder_model\n",
        " \n",
        "def freeze(model):\n",
        "    \"\"\"Freeze model weights in every layer.\"\"\"\n",
        "    for layer in model.layers:\n",
        "        layer.trainable = False\n",
        " \n",
        "        if isinstance(layer, keras.models.Model):\n",
        "            freeze(layer)\n",
        "    return model\n",
        " \n",
        "enc_model, dec_model = make_inference_models()\n",
        " \n",
        "freeze(enc_model).save('enc_model.h5')\n",
        "freeze(dec_model).save('dec_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StT4Gl-V_Q8u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import warnings\n",
        "import sys\n",
        "sys.stdout.write(\"\\033[1;34m\")\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "test_path_im='/content/drive/My Drive/test_img'\n",
        "dir_path_conversation = '/content/drive/My Drive/chatterbot_dataset_ita'\n",
        "test_im_len=len([name for name in os.listdir(test_path_im) if os.path.isfile(os.path.join(test_path_im, name))])\n",
        "len_data_vqa=2000\n",
        "input_im_size=64\n",
        "\n",
        "#questions and answers\n",
        "pre_ques = ['che cosa vedi']\n",
        "pre_answers = ['vedo una camera da letto', 'vedo una città con dei palazzi', 'ci sono delle persone ',\n",
        "               'una foresta con degli alberi', 'sono davanti ad una montagna', 'questo potrebbe essere un cane',\n",
        "               'un gatto', 'il traffico con delle macchine', 'vedo una scrivania', 'questa dovrebbe essere una sedia']\n",
        "questions = []\n",
        "answers = []\n",
        "\n",
        "for i in range(len_data_vqa):\n",
        "    questions.append(pre_ques[0])\n",
        "\n",
        "for i in range(int(len_data_vqa / 200)):\n",
        "    for n in range(200):\n",
        "        answers.append(pre_answers[i])\n",
        "\n",
        "for filepath in os.listdir(dir_path_conversation):\n",
        "    stream = open(dir_path_conversation + os.sep + filepath, 'r', encoding='utf-8')\n",
        "    text = stream.readlines()\n",
        "    for i in range(int(len(text) / 2) - 6):\n",
        "        questions.append(text[i + i].rstrip('\\n'))\n",
        "        answers.append(text[i + i + 1].rstrip('\\n'))\n",
        "\n",
        "#questions\n",
        "questions_lines = questions\n",
        "\n",
        "tokenizer = Tokenizer(oov_token=1)\n",
        "tokenizer.fit_on_texts( questions_lines )\n",
        "tokenized_eng_lines = tokenizer.texts_to_sequences( questions_lines )\n",
        "\n",
        "length_list = []\n",
        "for token_seq in tokenized_eng_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_input_length = np.amax( length_list )\n",
        "print( 'questions max length is {}'.format( max_input_length ))\n",
        "\n",
        "padded_eng_lines = pad_sequences( tokenized_eng_lines , maxlen=max_input_length , padding='post' )\n",
        "encoder_input_data = np.array( np.expand_dims(padded_eng_lines, 1))\n",
        "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
        "\n",
        "eng_word_dict = tokenizer.word_index\n",
        "num_eng_tokens = len( eng_word_dict )+1\n",
        "print( 'Number of questions tokens = {}'.format( num_eng_tokens))\n",
        "\n",
        "#answers\n",
        "lines_answers=answers\n",
        "answer_lines = []\n",
        "for line in range( len(lines_answers)):\n",
        "    answer_lines.append( '<START> ' + str(lines_answers[line]) + ' <END>' )\n",
        "\n",
        "tokenizer_a = Tokenizer()\n",
        "tokenizer_a.fit_on_texts( answer_lines )\n",
        "tokenized_mar_lines = tokenizer_a.texts_to_sequences( answer_lines )\n",
        "\n",
        "length_list = []\n",
        "for token_seq in tokenized_mar_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_output_length = np.amax( length_list )\n",
        "print( 'Answers max length is {}'.format( max_output_length ))\n",
        "\n",
        "padded_mar_lines = pad_sequences( tokenized_mar_lines , maxlen=max_output_length, padding='post' )\n",
        "decoder_input_data = np.array( padded_mar_lines )\n",
        "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
        "\n",
        "mar_word_dict = tokenizer_a.word_index\n",
        "num_mar_tokens = len( mar_word_dict )+1\n",
        "print( 'Number of Answers tokens = {}'.format( num_mar_tokens))\n",
        "\n",
        "#load model\n",
        "enc_model=keras.models.load_model('/content/enc_model.h5',compile=False)\n",
        "dec_model=keras.models.load_model('/content/dec_model.h5',compile=False)\n",
        "\n",
        "print('Test su seq2se2_cnn avviato...')\n",
        "\n",
        "while True:\n",
        " number_file=input('Scegliere il numero del file:')\n",
        " try:\n",
        "   if int(number_file)>test_im_len or int(number_file)<1:\n",
        "     print('File non trovato, riprova.')\n",
        "   else:\n",
        "     image=cv2.resize(cv2.imread(test_path_im+'/'+ str(number_file)+ '.jpg'),(input_im_size,input_im_size))/255.0\n",
        "     image=np.expand_dims([image],1)\n",
        "     question=input('Tu:')\n",
        "     question=pad_sequences(tokenizer.texts_to_sequences([question]), maxlen=max_input_length , padding='post')\n",
        "     question=np.expand_dims(question,1)\n",
        "     states_values = enc_model.predict([image,question])\n",
        "     empty_target_seq = np.zeros((1, 1))\n",
        "     empty_target_seq[0, 0] = mar_word_dict['start']\n",
        "     stop_condition = False\n",
        "     decoded_translation = ''\n",
        "     while not stop_condition:\n",
        "       dec_outputs, h, c = dec_model.predict([empty_target_seq] + states_values)\n",
        "       sampled_word_index = np.argmax(dec_outputs[0, -1, :])\n",
        "       sampled_word = None\n",
        "       for word, index in mar_word_dict.items():\n",
        "         if sampled_word_index == index:\n",
        "           decoded_translation += ' {}'.format(word)\n",
        "           sampled_word = word\n",
        "\n",
        "       if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
        "         stop_condition = True\n",
        "\n",
        "       empty_target_seq = np.zeros((1, 1))\n",
        "       empty_target_seq[0, 0] = sampled_word_index\n",
        "       states_values = [h, c]\n",
        "\n",
        "     print('AGI:' + decoded_translation.replace('end',''))\n",
        " except ValueError:\n",
        "   print(\"Si accettano solo numeri.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghuXDDBrhSDC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}